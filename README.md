# MULTILAYER PERCEPTRON

## ğŸš€ LANCEMENT DES PROGRAMMES

Set up le virtual env et la config du projet :
```bash
source venv/bin/activate
source venv/bin/activate
pip install -r requirements.txt
pip install -e .
```

Commandes scripts :
```bash
python scripts/process_data.py --path_csv_to_read data/data.csv --select_features three
python scripts/train.py --layer 24 24 24 --epochs 20 --loss binaryCrossentropy --batch_size 32 --learning_rate 0.0314
python scripts/validate.py
```
---

## ğŸ¯ OBJECTIF : DÃ‰TECTION DE CELLULES CANCÃ‰REUSES

Le dataset "Wisconsin Diagnostic Breast Cancer (WDBC)" a servi Ã  des chercheurs Ã  mettre au point un modÃ¨le pour identifier les cellules cancÃ©reuses malignes.

### ğŸ“Š Baseline de rÃ©fÃ©rence
- **MÃ©thode :** Multisurface Method-Tree (MSM-T) 
- **Performance :** 97.5% de prÃ©cision
- **Features utilisÃ©es :** 3 seulement
  - Worst Area (pire aire)
  - Worst Smoothness (pire lissage) 
  - Mean Texture (texture moyenne)

**Notre dÃ©fi :** Ã‰galer ou dÃ©passer ces performances avec un MLP !

---

## âœ… EXIGENCES 42

- [x] 2 couches cachÃ©es minimum
- [x] Architecture modulaire 
- [x] Activation softmax en sortie
- [x] Fonction de coÃ»t : log loss
- [x] Split train/validation
- [x] MÃ©triques affichÃ©es Ã  chaque epoch
- [x] Courbes d'apprentissage
- [x] Sauvegarde/chargement du modÃ¨le
- [x] Ã‰valuation avec cross-entropy

### âš ï¸ IncohÃ©rence dans l'Ã©noncÃ©
**Softmax** (quand on a 2 neurones) + **Binary Cross Entropy** (quand on a 1 neurone) 
â†’ **Solution :** ImplÃ©menter les deux architectures

---

## ğŸ”„ PIPELINE D'IMPLÃ‰MENTATION

### 1ï¸âƒ£ PREPROCESSING DES DONNÃ‰ES

#### Dataset info
- **569 Ã©chantillons** (357 bÃ©nignes, 212 malignes)
- **30 features** disponibles
- **Aucune valeur manquante**
- **Classes dÃ©sÃ©quilibrÃ©es** (62.7% vs 37.3%)

#### Ã‰tapes de preprocessing
1. **Nettoyage** : VÃ©rifier l'absence de NaN
2. **Split train/test** : Sans sklearn (implÃ©mentation manuelle)
3. **SÃ©lection des features** :
   - Histogrammes pour features discriminantes
   - Matrice de corrÃ©lation pour Ã©liminer redondance
   - Analyse de variance pour features informatives
4. **Standardisation** des donnÃ©es (recommandÃ© pour un MLP)
5. **Encodage** de la target (0/1 ou one-hot)

### 2ï¸âƒ£ ARCHITECTURE DU MLP

#### Structure gÃ©nÃ©rale
```
Input Layer (n_features) â†’ Hidden Layer 1 â†’ Hidden Layer 2 â†’ Output Layer
```

#### RÃ¨gles d'implÃ©mentation
- **Initialisation :** Poids alÃ©atoires entre -1 et 1 (`np.random.randn() * 0.1`)
- **Biais :** InitialisÃ©s Ã  zÃ©ro (`np.zeros((1, n_neurons))`)
- **ConnectivitÃ© :** inputs(n) = neurons(n-1)

#### Fonctions d'activation
- **Hidden layers :** ReLU (`max(0, x)`)
- **Output layer :** Softmax ou Sigmoid selon l'architecture

### 3ï¸âƒ£ ENTRAÃNEMENT

#### Forward Pass
```python
z = WÂ·X + b  # Combinaison linÃ©aire
a = activation(z)  # Activation
```

#### Backward Pass - ChaÃ®ne des gradients
```
dLoss/dW = dLoss/da Ã— da/dz Ã— dz/dW
```

**Pour chaque couche :**
1. Calculer `dLoss/da` (gradient de la loss)
2. Calculer `da/dz` (dÃ©rivÃ©e de l'activation)
3. Calculer `dz/dW` (gradient par rapport aux poids)
4. Mettre Ã  jour : `W -= learning_rate * dLoss/dW`

#### Loss Functions
- **Binary Cross Entropy :** `-(y*log(p) + (1-y)*log(1-p))`
- **Categorical Cross Entropy :** `-Î£(y_true * log(y_pred))`

### 4ï¸âƒ£ Ã‰VALUATION

#### MÃ©triques principales

| MÃ©trique | Formule | Usage |
|----------|---------|-------|
| **Accuracy** | (TP + TN) / Total | Performance globale |
| **Precision** | TP / (TP + FP) | "Quand je dis cancer, ai-je raison ?" |
| **Recall** | TP / (TP + FN) | "Est-ce que je trouve tous les cancers ?" |
| **F1-Score** | 2Ã—(PrecisionÃ—Recall)/(Precision+Recall) | Ã‰quilibre P/R |

#### Rappel : la matrice de confusion
```
              PrÃ©diction
           |  B  |  M  |
RÃ©alitÃ© B  | TN  | FP  |
        M  | FN  | TP  |
```

âš ï¸ **En mÃ©dical : Minimiser les False Negatives** (cancers ratÃ©s)

#### LES SIGNES QUE LE MODELE NE MARCHE PAS CORRECTEMENT :
- **Overfitting :** train_accuracy >> val_accuracy
- **Underfitting :** des performances faibles partout
- **InstabilitÃ© :** des courbes qui oscillent

---

## ğŸ¯ LES SCENARIOS POSSIBLES :

- **âœ… Situation normale**
Train: 90% â†’ Test: 87%   (LÃ©gÃ¨re baisse, c'est normal)

- **âš ï¸ Overfitting**
Train: 99% â†’ Test: 75%   (Grosse chute = mÃ©morisation)

- **ğŸ˜± Underfitting**
Train: 60% â†’ Test: 58%   (Les deux faibles = modÃ¨le trop simple)

-**ğŸ‰ Situation idÃ©ale**
Train: 92% â†’ Test: 91%   (TrÃ¨s proche = bon modÃ¨le)